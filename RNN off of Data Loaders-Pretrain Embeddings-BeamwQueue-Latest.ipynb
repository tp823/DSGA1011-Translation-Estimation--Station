{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building an RNN for Machine Translation\n",
    "## Initial Data Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file we will read in the data for the Vietnamese and Chinese to Engish corpuses, build a token2id and char2id mapping, vocabularies and data loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an RNN for Machine Translation\n",
    "Initial Data Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Modules\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch import optim\n",
    "import pickle as pkl\n",
    "import random\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import io\n",
    "from collections import Counter\n",
    "import sacrebleu\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#Global Variables\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in pre-trained fasttext embeddings for the three languages\n",
    "### Building loaded embeddings, token2id, id2token and ordered words for all languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words embedded is 100,000\n",
      "Total number of words embedded is 100,000\n",
      "Total number of words embedded is 100,000\n"
     ]
    }
   ],
   "source": [
    "# Load Pre-trained Word Vectors\n",
    "def load_embeddings(word2vec, word2id, embedding_dim):\n",
    "    embeddings = np.zeros((len(word2id), embedding_dim))\n",
    "    for word, index in word2id.items():\n",
    "        try:\n",
    "            embeddings[index] = word2vec[word]\n",
    "\n",
    "        except KeyError:\n",
    "            embeddings[index] = np.random.normal(scale=0.6, size=(300,))\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "def load_vectors(fname, num_vecs=None):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    n, d = map(int, fin.readline().split())\n",
    "    data = {}\n",
    "    for line in fin:\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "\n",
    "        if num_vecs is None:\n",
    "            pass\n",
    "        else:\n",
    "            if len(data) + 1 > num_vecs:\n",
    "                break\n",
    "    return data\n",
    "\n",
    "\n",
    "def data_dictionary(tokens, vocab_size_limit):\n",
    "    token_counter = Counter()\n",
    "    for token in tokens:\n",
    "        token_counter[token] += 1\n",
    "\n",
    "    vocab, count = zip(*token_counter.most_common(vocab_size_limit))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(4, 4 + len(vocab))))\n",
    "    id2token = ['<pad>', '<unk>','<sos>','<eos>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX\n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    token2id['<sos>'] = SOS_IDX\n",
    "    token2id['<eos>'] = EOS_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "#Load Word Embeddings\n",
    "\n",
    "path= '../pretrained_embeddings/'\n",
    "\n",
    "en_loaded_embeddings = load_vectors(path +'wiki.en.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(en_loaded_embeddings)))\n",
    "\n",
    "vi_loaded_embeddings = load_vectors(path+'wiki.vi.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(vi_loaded_embeddings)))\n",
    "\n",
    "zh_loaded_embeddings = load_vectors(path+'wiki.zh.vec',100000)\n",
    "print(\"Total number of words embedded is {:,d}\".format(len(zh_loaded_embeddings)))\n",
    "\n",
    "\n",
    "#Create token2Id, token2Id\n",
    "en_token2id, en_id2token = data_dictionary(list(en_loaded_embeddings.keys()), 100000)\n",
    "vi_token2id, vi_id2token = data_dictionary(list(vi_loaded_embeddings.keys()), 100000)\n",
    "zh_token2id, zh_id2token = data_dictionary(list(zh_loaded_embeddings.keys()), 100000)\n",
    "\n",
    "\n",
    "#Create Emedding Matrix\n",
    "en_loaded_embeddings=load_embeddings(en_loaded_embeddings,en_token2id,300)\n",
    "vi_loaded_embeddings=load_embeddings(vi_loaded_embeddings,vi_token2id,300)\n",
    "zh_loaded_embeddings=load_embeddings(zh_loaded_embeddings,zh_token2id,300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading in training, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vi -> En | Training Examples: 133317\n",
      "Vi -> En | Training Examples: 133317 \n",
      "\n",
      "Vi -> En | Validation Examples: 1268\n",
      "Vi -> En | Validation Examples: 1268 \n",
      "\n",
      "Vi -> En | Testing Examples: 1553\n",
      "Vi -> En | Testing Examples: 1553 \n",
      "\n",
      "Zh -> En | Training Examples: 213377\n",
      "Zh -> En | Training Examples: 213377 \n",
      "\n",
      "Zh -> En | Validation Examples: 1261\n",
      "Zh -> En | Validation Examples: 1261 \n",
      "\n",
      "Zh -> En | Testing Examples: 1397\n",
      "Zh -> En | Testing Examples: 1397 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loading in the Vietnamese -> En datasets\n",
    "path1= '../project_data/en-vi/'\n",
    "\n",
    "train_vi_en = []\n",
    "with open(path1 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "train_vi_vi = []\n",
    "with open(path1 + 'train.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_vi_vi.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_en = []\n",
    "with open(path1 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "val_vi_vi = []\n",
    "with open(path1 +'dev.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "test_vi_en = []\n",
    "with open(path1 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "test_vi_vi = []\n",
    "with open(path1 + 'test.tok.vi') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_vi_vi.append(line.strip().lower().split(' '))\n",
    "        \n",
    "        \n",
    "        \n",
    "#Loading in the Chinese -> En datasets\n",
    "path2= '../project_data/en-zh/'\n",
    "\n",
    "train_zh_en = []\n",
    "with open(path2 +'train.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        train_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "i=0\n",
    "train_zh_zh = []\n",
    "fin = io.open(path2 +'train.tok.zh', 'r', encoding='utf-8',newline= '\\n', errors='ignore')\n",
    "for line in fin:\n",
    "    if i % 2 == 0 :\n",
    "        train_zh_zh.append(line.rstrip().split(' '))\n",
    "    i+=1 \n",
    "\n",
    "val_zh_en = []\n",
    "with open(path2 + 'dev.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        val_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "i=0\n",
    "val_zh_zh = []\n",
    "fin = io.open(path2 +'dev.tok.zh', 'r', encoding='utf-8',newline= '\\n', errors='ignore')\n",
    "for line in fin:\n",
    "    if i % 2 == 0 :\n",
    "        val_zh_zh.append(line.rstrip().split(' '))\n",
    "    i+=1\n",
    "\n",
    "test_zh_en = []\n",
    "with open(path2 +'test.tok.en') as inputfile:\n",
    "    for line in inputfile:\n",
    "        test_zh_en.append(line.strip().lower().split(' '))\n",
    "\n",
    "i=0\n",
    "test_zh_zh = []\n",
    "fin = io.open(path2 +'test.tok.zh', 'r', encoding='utf-8',newline= '\\n', errors='ignore')\n",
    "for line in fin:\n",
    "    if i % 2 == 0 :\n",
    "        test_zh_zh.append(line.rstrip().split(' '))\n",
    "    i+=1\n",
    "\n",
    "#Sanity Checking\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_en)))\n",
    "print(\"Vi -> En | Training Examples: \"+str(len(train_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_en)))\n",
    "print(\"Vi -> En | Validation Examples: \"+str(len(val_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_en)))\n",
    "print(\"Vi -> En | Testing Examples: \"+str(len(test_vi_vi)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_en)))\n",
    "print(\"Zh -> En | Training Examples: \"+str(len(train_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_en)))\n",
    "print(\"Zh -> En | Validation Examples: \"+str(len(val_zh_zh)), '\\n')\n",
    "\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_en)))\n",
    "print(\"Zh -> En | Testing Examples: \"+str(len(test_zh_zh)), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preserve original data for evaluation\n",
    "train_vi_en_orig = train_vi_en\n",
    "train_vi_vi_orig = train_vi_vi\n",
    "val_vi_en_orig = val_vi_en\n",
    "val_vi_vi_orig = val_vi_vi\n",
    "test_vi_en_orig = test_vi_en\n",
    "test_vi_vi_orig = test_vi_vi\n",
    "\n",
    "train_zh_en_orig = train_zh_en\n",
    "train_zh_zh_orig = train_zh_zh\n",
    "val_zh_en_orig = val_zh_en\n",
    "val_zh_zh_orig = val_zh_zh\n",
    "test_zh_en_orig = test_zh_en\n",
    "test_zh_zh_orig = test_zh_zh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VI_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_vi_en+train_vi_vi], 90))+1\n",
    "ZH_EN_MAX_LENGTH = int(np.percentile([len(sentence) for sentence in train_zh_en+train_zh_zh], 90))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoding_tokens(sentence, language, translator):\n",
    "    if language== 'English':\n",
    "        token2id = en_token2id\n",
    "    elif language== 'Vietnamese':\n",
    "        token2id = vi_token2id\n",
    "    elif language== 'Chinese':\n",
    "        token2id = zh_token2id\n",
    "    tokens = [token2id[token] if token in token2id else UNK_IDX for token in sentence]\n",
    "    if translator == 'vi':\n",
    "        max_len = VI_EN_MAX_LENGTH-1\n",
    "    elif translator == 'zh':\n",
    "        max_len = ZH_EN_MAX_LENGTH-1\n",
    "    tokens=tokens[:max_len]\n",
    "    return tokens\n",
    "\n",
    "def encoding_dataset(dataset, language, translator):\n",
    "    data = [encoding_tokens(tokens, language, translator) for tokens in dataset] \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vi_en = encoding_dataset(train_vi_en, 'English', 'vi')\n",
    "train_vi_vi = encoding_dataset(train_vi_vi, 'Vietnamese', 'vi')\n",
    "test_vi_en = encoding_dataset(test_vi_en, 'English', 'vi')\n",
    "test_vi_vi = encoding_dataset(test_vi_vi, 'Vietnamese', 'vi')\n",
    "val_vi_en = encoding_dataset(val_vi_en, 'English', 'vi')\n",
    "val_vi_vi = encoding_dataset(val_vi_vi, 'Vietnamese', 'vi')\n",
    "\n",
    "train_zh_en = encoding_dataset(train_zh_en, 'English', 'zh')\n",
    "train_zh_zh = encoding_dataset(train_zh_zh, 'Chinese', 'zh')\n",
    "test_zh_en = encoding_dataset(test_zh_en, 'English', 'zh')\n",
    "test_zh_zh = encoding_dataset(test_zh_zh, 'Chinese', 'zh')\n",
    "val_zh_en = encoding_dataset(val_zh_en, 'English', 'zh')\n",
    "val_zh_zh = encoding_dataset(val_zh_zh, 'Chinese', 'zh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class translationDataset(Dataset):\n",
    "    def __init__(self, data_list, target_list):\n",
    "        self.data_list=data_list\n",
    "        self.target_list=target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.target_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        data = self.data_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        label = self.target_list[key][:MAX_SAMPLE_LENGTH]\n",
    "        return [data, len(data), label, len(label)]\n",
    "\n",
    "def translation_collate_func(batch):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for datum in batch:\n",
    "        padded_data = np.pad(np.array(datum[0]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_data)\n",
    "        padded_label = np.pad(np.array(datum[2]+[EOS_IDX]), \n",
    "                                pad_width=((0,MAX_SAMPLE_LENGTH-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        label_list.append(padded_label)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.from_numpy(np.array(label_list))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VI -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = VI_EN_MAX_LENGTH\n",
    "\n",
    "vi_en_train_dataset = translationDataset(train_vi_vi, train_vi_en)\n",
    "vi_en_train_loader = torch.utils.data.DataLoader(dataset=vi_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_val_dataset = translationDataset(val_vi_vi, val_vi_en)\n",
    "vi_en_val_loader = torch.utils.data.DataLoader(dataset=vi_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "vi_en_test_dataset = translationDataset(test_vi_vi, test_vi_en)\n",
    "vi_en_test_loader = torch.utils.data.DataLoader(dataset=vi_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZH -> EN | dataloaders\n",
    "MAX_SAMPLE_LENGTH = ZH_EN_MAX_LENGTH\n",
    "\n",
    "zh_en_train_dataset = translationDataset(train_zh_zh, train_zh_en)\n",
    "zh_en_train_loader = torch.utils.data.DataLoader(dataset=zh_en_train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_val_dataset = translationDataset(val_zh_zh, val_zh_en)\n",
    "zh_en_val_loader = torch.utils.data.DataLoader(dataset=zh_en_val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "zh_en_test_dataset = translationDataset(test_zh_zh, test_zh_en)\n",
    "zh_en_test_loader = torch.utils.data.DataLoader(dataset=zh_en_test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=translation_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showPlot(points, string):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.plot(points)\n",
    "    plt.title(string)\n",
    "    plt.savefig((string+'.png'), dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, language, drop_rate=0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.language = language\n",
    "        if language == 'Vietnamese':\n",
    "             self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vi_loaded_embeddings), freeze=True)\n",
    "        elif language == 'Chinese':\n",
    "            self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(vi_loaded_embeddings), freeze=True)\n",
    "        self.gru = nn.GRU(300, hidden_size)\n",
    "        self.dropout = nn.Dropout(drop_rate)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.embedding(input)\n",
    "        output = self.dropout(embedded)\n",
    "        output, hidden = self.gru(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "    \n",
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, drop_rate=0):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(en_loaded_embeddings), freeze=True)\n",
    "        self.gru = nn.GRU(hidden_size + 300, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, len(en_token2id))\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.dropout = nn.Dropout(p=drop_rate)\n",
    "\n",
    "    def forward(self, input, hidden, enc_output):\n",
    "        input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input)).unsqueeze(0)\n",
    "        embedded_concat = torch.cat((embedded, enc_output), dim=2)\n",
    "        output, hidden = self.gru(embedded_concat, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_tensor = input_tensor.transpose(0,1)\n",
    "    target_tensor = target_tensor.transpose(0,1)\n",
    "    \n",
    "    max_length = input_tensor.size(0)\n",
    "    batch_size = input_tensor.size(1)\n",
    "    vocab_size = len(en_token2id)\n",
    "    \n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "    \n",
    "    encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "    encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "    decoder_input = input_tensor[0,:]\n",
    "    decoder_hidden = encoder_hidden\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]\n",
    "    else:\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / max_length\n",
    "\n",
    "def trainIters(loader, encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    language = encoder.language\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for iter in range(1, n_iters + 1):\n",
    "        for i, (data, labels) in enumerate(loader):\n",
    "            input_tensor = data\n",
    "            target_tensor = labels\n",
    "    \n",
    "            loss = train(input_tensor, target_tensor, encoder,\n",
    "                         decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "            print_loss_total += loss\n",
    "            plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "    showPlot(plot_losses, language)\n",
    "    return plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 22s (- 21m 19s) (1 10%) 288.1795\n",
      "4m 56s (- 19m 45s) (2 20%) 284.9752\n",
      "6m 55s (- 16m 9s) (3 30%) 185.2640\n",
      "8m 46s (- 13m 9s) (4 40%) 141.6142\n",
      "12m 9s (- 12m 9s) (5 50%) 112.7830\n",
      "14m 9s (- 9m 26s) (6 60%) 172.4425\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-45d733928d27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mencoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Vietnamese'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdecoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvi_en_val_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-bcaf14514d85>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             loss = train(input_tensor, target_tensor, encoder,\n\u001b[0;32m--> 107\u001b[0;31m                          decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-bcaf14514d85>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nlpclass/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Training Model\n",
    "teacher_forcing_ratio = 0.5\n",
    "hidden_size = 256\n",
    "batch_size = 128\n",
    "encoder1 = EncoderRNN(hidden_size, 'Vietnamese', drop_rate = 0.1).to(device)\n",
    "decoder1 = DecoderRNN(hidden_size).to(device)\n",
    "trainIters(vi_en_val_loader, encoder1, decoder1, n_iters=10, print_every=1,plot_every=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#beam data structure\n",
    "        \n",
    "class Beam_Node(object):\n",
    "    def __init__(self, hiddenstate, previousNode, wordId, Prob, length):\n",
    "        self.hidden = hiddenstate\n",
    "        self.prevNode = previousNode\n",
    "        self.wordId = wordId\n",
    "        self.prob = Prob\n",
    "        self.length = length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    if lang == 'Vietnamese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in vi_token2id:\n",
    "                out.append(vi_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'English':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in en_token2id:\n",
    "                out.append(en_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    elif lang == 'Chinese':\n",
    "        out = []\n",
    "        for word in sentence:\n",
    "            if word in zh_token2id:\n",
    "                out.append(zh_token2id[word])\n",
    "            else:\n",
    "                out.append(UNK_IDX)\n",
    "    return out\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_IDX)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, input_lang):\n",
    "    with torch.no_grad():   \n",
    "        \n",
    "        #for i, (data, labels) in enumerate(vi_en_train_loader):\n",
    "        #    input_tensor = data\n",
    "        \n",
    "       \n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        max_length = input_tensor.size(0)\n",
    "        input_tensor = input_tensor.transpose(0,1)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        #print(input_length)\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        #encoder_outputs = torch.zeros(max_length, encoder.hidden_size)\n",
    "        #encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
    "\n",
    "        #for ei in range(input_length):\n",
    "        #    encoder_output, encoder_hidden = encoder(\n",
    "        #        input_tensor)\n",
    "        #    encoder_outputs[ei] = encoder_output[0,0]\n",
    "            \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "        encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "        #decoder_input = torch.tensor([[SOS_IDX]] * batch_size)\n",
    "        decoder_input = input_tensor[0,:]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        #decoder_attentions = torch.zeros(max_length, max_length)\n",
    "                \n",
    " #       for di in range(max_length):\n",
    " #           decoder_output, decoder_hidden = decoder(\n",
    "  #             decoder_input, decoder_hidden, encoder_hidden)\n",
    "          #  print(decoder_output)\n",
    "          #  print(decoder_hidden)\n",
    "  #          topv, topi = decoder_output.topk(1, di)\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "  #          decoder_input = topi.squeeze().detach()\n",
    "  #          print(decoder_input[di].item())\n",
    "  #          if decoder_input[di].item()== EOS_IDX:\n",
    "  #              decoded_words.append('<EOS>')\n",
    "  #              break\n",
    "  #          else:\n",
    "  #              decoded_words.append(en_id2token[decoder_input[di].item()])\n",
    "  #          print(decoded_words)\n",
    "  #          decoder_input = decoder_input[di]\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "               decoder_input, decoder_hidden, encoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            #decoder_attentions[di] = decoder_attention.data\n",
    "            if decoder_input[di].item() == EOS_IDX:\n",
    "                break\n",
    "            else:\n",
    "                decoded_words.append(en_id2token[decoder_input[di].item()])\n",
    "                \n",
    "        return decoded_words#, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "import operator\n",
    "\n",
    "def evaluate_beam(encoder, decoder, sentence, input_lang, beam_size=3):\n",
    "    with torch.no_grad():\n",
    "        beam_size = beam_size + 1 #add extra to account for padding\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        max_length = input_tensor.size(0)\n",
    "        batch_size = max_length\n",
    "        input_tensor = input_tensor.transpose(0,1)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        \n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor)\n",
    "        encoder_outputs = encoder_output[0,0]\n",
    "\n",
    "        decoder_input = input_tensor[0,:]\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        decoded_words = []\n",
    "        decoded_sentence = []\n",
    "\n",
    "        beam_storage = []\n",
    "        for i in range(beam_size-1):\n",
    "            beam_storage.append([])\n",
    "        \n",
    "        #run beam search for each word in input\n",
    "        for di in range(max_length):\n",
    "            beams = []\n",
    "            for x in range(beam_size**2):\n",
    "                beams.append([])\n",
    "\n",
    "            # starting node -  self, hidden, prevNode, wordId, prob, length\n",
    "            decoder_input = input_tensor[0,:]\n",
    "            node = Beam_Node(decoder_hidden, None, input_tensor[0,:], 0, 1)\n",
    "            nodes = PriorityQueue()\n",
    "            nodes.put((-node.prob, node))\n",
    "            pqueue_size = 1\n",
    "\n",
    "            # start beam search\n",
    "            while True:\n",
    "                # give up when sentence length too large\n",
    "                if pqueue_size > 2000: \n",
    "                    print(\"ended early\")\n",
    "                    break\n",
    "\n",
    "                score, node = nodes.get()\n",
    "                decoder_input = node.wordId\n",
    "                decoder_hidden = node.hidden\n",
    "\n",
    "                if node.wordId[0].item() == EOS_IDX and node.prevNode != None:\n",
    "                    decoded_words.append((score, node))\n",
    "                    break\n",
    "\n",
    "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hidden)\n",
    "                prob, idx = torch.topk(decoder_output, beam_size)\n",
    "                nextnodes = []\n",
    "\n",
    "                for next_n in range(beam_size):\n",
    "                    decoded = idx[:,next_n]\n",
    "                    p = prob[0][next_n].item()\n",
    "\n",
    "                    new_node = Beam_Node(decoder_hidden, node, decoded, node.prob + p, node.length + 1)\n",
    "                    score = new_node.prob\n",
    "                    nextnodes.append((-score, new_node))\n",
    "\n",
    "                # add to queue\n",
    "                for i in range(len(nextnodes)):\n",
    "                    score, nn = nextnodes[i]\n",
    "                    nodes.put((score, nn))\n",
    "                    # increase priority queue size\n",
    "                    pqueue_size += len(nextnodes) - 1\n",
    "\n",
    "            # choose best path and trace back\n",
    "            if len(decoded_words) == 0:\n",
    "                decoded_words = [nodes.get() for _ in range(1)]    \n",
    "\n",
    "\n",
    "            sentence = []\n",
    "            for score, n in sorted(decoded_words, key=operator.itemgetter(0)):\n",
    "                words = []\n",
    "                words.append(en_id2token[n.wordId[0].item()])\n",
    "                # get prev nodes\n",
    "                while n.prevNode != None:\n",
    "                    n = n.prevNode\n",
    "                    words.append(en_id2token[n.wordId[0].item()])\n",
    "                    #words.append(n.wordId)\n",
    "\n",
    "                words = words[::-1]\n",
    "                sentence.append(words)  \n",
    "            \n",
    "            decoded_sentence.append(sentence)\n",
    "\n",
    "        return decoded_sentence            \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['tôi', 'sẽ', 'tiếp_tục', 'công_việc', 'thúc_giục', 'để', 'tìm_ra', 'giải_pháp', 'cho', 'những', 'vấn_đề', 'tại', 'bộ', 'tài_chính', '.']\n",
      "= ['i', '&apos;m', 'going', 'to', 'continue', 'the', 'work', 'to', 'press', 'on', ',', 'to', 'get', 'some', 'resolution', 'of', 'those', 'matters', 'at', 'the', 'ministry', 'of', 'finance', '.']\n",
      "beam [[['took', 'topsoil', '<eos>']], [['took', 'topsoil', '<eos>'], ['took', 'topsoil', '<eos>']], [['took', 'topsoil', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']], [['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'kirche', '<eos>'], ['took', 'topsoil', '<eos>'], ['took', 'unchanged', 'kirche', '<eos>']]]\n",
      "< ccffcc . <pad> <pad> <pad> . <pad> <pad> . . <pad> . <pad> <pad> . <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "index = randint(0, len(train_vi_en_orig))\n",
    "sentence1 = train_vi_vi_orig[index] \n",
    "sentence2 = train_vi_en_orig[index]            \n",
    "\n",
    "print('>', sentence1)\n",
    "print('=', sentence2)\n",
    "output_words = evaluate_beam(encoder1, decoder1, sentence1, \"Vietnamese\")\n",
    "print(\"beam\", output_words)\n",
    "output_words = evaluate(encoder1, decoder1, sentence1, \"Vietnamese\")\n",
    "output_sentence = ' '.join(output_words)\n",
    "print('<', output_sentence)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "def evaluateRandomly(encoder, decoder, language, n=10):\n",
    "    for i in range(n):\n",
    "        if language == 'Vietnamese':\n",
    "            index = randint(0, len(train_vi_en_orig))\n",
    "            sentence1 = train_vi_vi_orig[index] \n",
    "            sentence2 = train_vi_en_orig[index]\n",
    "        elif language == 'Chinese':\n",
    "            index = randint(0, len(train_zh_en_orig))\n",
    "            sentence1 = train_zh_zh_orig[index]\n",
    "            sentence2 = train_zh_en_orig[index]\n",
    "        \n",
    "        print('>', sentence1)\n",
    "        print('=', sentence2)\n",
    "        output_words = evaluate(encoder, decoder, sentence1, language)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ['chong_chóng', 'quay', 'là', 'một', '\"', 'đặc_tính', 'hợp', 'trội', '\"', 'xảy_ra', 'do', 'tương_tác', 'giữa', 'những', 'chú', 'chó', 'con', 'mà', 'quy_luật', 'duy_nhất', 'là', 'cố_gắng', 'duy_trì', 'sự', 'tiếp_cận', 'của', 'chúng', 'với', 'tô', 'sữa', '.', 'và', 'do', 'đó', ',', 'đẩy', 'chúng', 'đi', 'theo', 'một', 'hướng', 'ngẫu_nhiên', '.']\n",
      "= ['the', 'pinwheel', 'is', 'an', 'emergent', 'property', 'of', 'the', 'interactions', 'between', 'puppies', 'whose', 'only', 'rule', 'is', 'to', 'try', 'to', 'keep', 'access', 'to', 'the', 'milk', 'and', 'therefore', 'to', 'push', 'in', 'a', 'random', 'direction', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['sally', 'tiếp_lời', ':', '\"', 'cho', 'sự_kiện', 'mùa_hè', 'ở', 'trường', 'nyu.', '\"']\n",
      "= ['sally', ':', '&quot;', 'for', 'this', 'summer', 'program', 'at', 'nyu', '.', '&quot;']\n",
      "< \n",
      "\n",
      "> ['như', 'một', 'câu_nói', ',', 'họ', 'biết', 'rằng', '\"', 'tính_cách', 'thực_sự', 'của', 'bạn', 'đang', 'lẩn_khuất', 'trong', 'bóng_tối', '.', '\"']\n",
      "= ['they', 'know', ',', 'as', 'someone', 'once', 'said', ',', '&quot;', 'character', '&apos;s', 'who', 'you', 'are', 'in', 'the', 'dark', '.', '&quot;']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['sau', 'trải', 'niệm', 'này', ',', 'thầy_giáo', 'của', 'tôi', ',', 'thầy', 'shilale', ',', 'đã', 'mang', 'những', 'quyển', 'chuyện', 'hình', 'này', ',', 'và', 'tôi', 'nghĩ', ':', '\"', 'chuyện', 'hình', 'cho', 'trẻ_em', '!', '\"']\n",
      "= ['so', 'after', 'this', 'experience', ',', 'my', 'art', 'teacher', ',', 'mr.', 'shilale', ',', 'he', 'brought', 'in', 'these', 'picture', 'books', ',', 'and', 'i', 'thought', ',', '&quot;', 'picture', 'books', 'for', 'kids', '!', '&quot;']\n",
      "< \n",
      "\n",
      "> ['con', 'muốn', 'người', 'lan', 'rộng', 'sự', 'nổi_tiếng', 'của', 'con', 'qua', 'mọi', 'vùng', 'miền', '.']\n",
      "= ['i', 'want', 'you', 'to', 'spread', 'the', 'fame', 'of', 'my', 'name', 'through', 'every', 'land', '.']\n",
      "< \n",
      "\n",
      "> ['và', 'thế_kỷ', 'thứ', '13', ',', 'có', 'nhiều', 'hàng', 'hơn', 'và', 'những', 'hình_dáng', 'mới', 'của', 'nốt_nhạc', 'được', 'khoá', 'lại', 'trong', 'khái_niệm', 'của', 'giai_điệu', 'một_cách', 'chính_xác', ',', 'và', 'điều', 'này', 'dẫn', 'đến', 'việc', 'hình_thành', 'nên', 'những', 'nốt_nhạc', 'mà', 'chúng_ta', 'có', 'ngày_nay', '.']\n",
      "= ['and', 'then', 'in', 'the', '13th', 'century', ',', 'more', 'lines', 'and', 'new', 'shapes', 'of', 'notes', 'locked', 'in', 'the', 'concept', 'of', 'the', 'tune', 'exactly', ',', 'and', 'that', 'led', 'to', 'the', 'kind', 'of', 'notation', 'we', 'have', 'today', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> cahokia <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['nó', 'là', 'một', 'loài', 'sinh_vật', 'rất', 'cô_độc', '.']\n",
      "= ['it', '&apos;s', 'a', 'very', 'solitary', 'creature', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['một', 'bên', ',', 'chúng_ta', 'có', '1,2', 'kg', ',', 'và', 'mặt', 'kia', 'là', '0,6', 'kg', '.']\n",
      "= ['at', 'the', 'one', 'hand', ',', 'we', 'have', '1.2', 'kilos', ',', 'and', 'at', 'the', 'other', 'hand', '0.6', 'kilos', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['với', 'một', 'tâm_trạng', 'không', 'vui', '.', 'hãy', 'nghĩ', 'về', 'điều', 'này', '.']\n",
      "= ['she', '&apos;s', 'not', 'amused', '.', 'let', '&apos;s', 'think', 'about', 'it', '.']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n",
      "> ['nhưng', 'may_thay', ',', 'có', 'một', 'số_ít', ',', 'một_số', 'đáng', 'tự_hào', '-', 'như', 'chị', 'đây', 'khuyên', 'tôi', 'nên', 'có', 'bài', 'nói', 'như', 'vậy', '.', 'và', 'tôi', 'hỏi', 'bản_thân', ',', 'câu_hỏi', 'mà', 'mark', 'zuckerberg', 'người', 'sáng_lập', 'ra', 'facebook', 'và', 'cũng', 'là', 'sếp', 'của', 'tôi', ',', 'đã', 'hỏi', 'tất_cả', 'chúng_tôi', ',', 'rằng', ',', 'tôi', 'sẽ', 'làm', 'gì', 'nếu_không', 'cảm_thấy', 'sợ_hãi', '.']\n",
      "= ['but', 'fortunately', ',', 'there', 'were', 'the', 'few', ',', 'the', 'proud', '--', 'like', 'you', '--', 'who', 'told', 'me', 'i', 'should', 'give', 'the', 'speech', ',', 'and', 'i', 'asked', 'myself', 'the', 'question', 'mark', 'zuckerberg', 'might', '--', 'the', 'founder', 'of', 'facebook', 'and', 'my', 'boss', '--', 'asks', 'all', 'of', 'us', ',', 'which', 'is', ',', 'what', 'would', 'i', 'do', 'if', 'i', 'wasn', '&apos;t', 'afraid', '?']\n",
      "< <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = VI_EN_MAX_LENGTH\n",
    "evaluateRandomly(encoder1, decoder1, \"Vietnamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate BLEU score on corpus level\n",
    "def BLEU(encoder, decoder, language):\n",
    "    hypotheses = \"\"\n",
    "    targets = \"\"\n",
    "    if language == 'Vietnamese':\n",
    "        inputs = val_vi_vi_orig\n",
    "        labels = val_vi_en_orig\n",
    "    else:\n",
    "        inputs = val_zh_zh_orig\n",
    "        labels = val_zh_zh_orig\n",
    "        \n",
    "    for sentence in inputs:\n",
    "        output = evaluate(encoder, decoder, sentence, language)\n",
    "        for word in output:\n",
    "            hypotheses = hypotheses + \" \" + word\n",
    "\n",
    "    #targets\n",
    "    for sentence in labels:\n",
    "        for word in sentence:\n",
    "            if word in en_id2token:\n",
    "                targets = targets + \" \" + word\n",
    "            else:\n",
    "                targets = targets + \" \" + '<unk>'\n",
    "\n",
    "    score = sacrebleu.corpus_bleu(hypotheses, targets)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU(score=0.020322293857056525, counts=[2273, 50, 1, 0], totals=[75975, 75974, 75973, 75972], precisions=[2.9917736097400462, 0.06581198831179087, 0.0013162570913350796, 0.0006581372084452166], bp=1.0, sys_len=75975, ref_len=29000)\n"
     ]
    }
   ],
   "source": [
    "BLEU(encoder1, decoder1, 'Vietnamese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
